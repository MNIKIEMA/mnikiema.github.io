{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2310d7c2",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title:  Batching with SBERT and LanceDB\n",
    "description: Retrieval with SBERT and LanceDB\n",
    "author: \"Mahamadi NIKIEMA\"\n",
    "thumbnail-img: profile.jpg\n",
    "tags: [Python, Scraping, Podcast]\n",
    "date:   2024-12-29 21:55:51 +0200\n",
    "categories: scraping\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca94b104",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import  SentenceTransformer\n",
    "from lancedb.embeddings import get_registry\n",
    "from lancedb.db import DBConnection\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from lancedb.embeddings import EmbeddingFunction\n",
    "from lancedb.table import Table\n",
    "from typing import Literal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cd865dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(batch, model: SentenceTransformer, column: str = \"chunk\"):\n",
    "    \"\"\"Get embeddings for a batch of text using the specified model\n",
    "    \"\"\"\n",
    "    embeddings = model.encode(batch[column])\n",
    "    return {\"vector\": embeddings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4f8434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_lancedb_table(\n",
    "    db: DBConnection,\n",
    "    table_name: str,\n",
    "    all_docs,\n",
    "    embedding_model: str = \"sentence-transformers\",\n",
    "    model_name: str = \"all-MiniLM-L6-v2\",\n",
    "):\n",
    "    embd_func: EmbeddingFunction = get_registry().get(embedding_model)\n",
    "    func = embd_func.create(name=model_name)\n",
    "\n",
    "    class Chunk(LanceModel):\n",
    "        id: str\n",
    "        chunk: str = func.SourceField()\n",
    "        vector: Vector = func.VectorField()  # type: ignore\n",
    "        vector: Vector(func.ndims()) = func.VectorField()  # type: ignore\n",
    "\n",
    "    if table_name in db.table_names() and db.open_table(table_name).count_rows() > 0:\n",
    "        print(f\"Table {table_name} already exists\")\n",
    "        table = db.open_table(table_name)\n",
    "        table.create_fts_index(\"chunk\", replace=True)\n",
    "        return table\n",
    "\n",
    "    table = db.create_table(table_name, schema=Chunk, mode=\"overwrite\")\n",
    "    table.add(all_docs)\n",
    "    print(f\"Table {table_name} created with {len(all_docs)} chunks\")\n",
    "    table.create_fts_index(\"chunk\", replace=True)\n",
    "    print(f\"{table.count_rows()} chunks ingested into the database\")\n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5cfcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(\n",
    "    question: str,\n",
    "    table: Table,\n",
    "    max_k=25,\n",
    "    mode: Literal[\"vector\", \"fts\", \"hybrid\"] = \"vector\",\n",
    "    ):\n",
    "    try:\n",
    "        if mode == \"fts\" or mode == \"hybrid\":\n",
    "            results = table.search(\n",
    "                query=question, vector_column_name=None, query_type=mode\n",
    "            ).limit(max_k)\n",
    "        else:\n",
    "            results = table.search(question, query_type=mode).limit(max_k)\n",
    "\n",
    "        return [\n",
    "            {\"id\": result[\"id\"], \"chunk\": result[\"chunk\"]}\n",
    "            for result in results.to_list()\n",
    "        ]\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62cc01a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_recall(predictions: list[str], gt: list[str]):\n",
    "    # Calculate the proportion of relevant items that were retrieved\n",
    "    return len([label for label in gt if label in predictions]) / len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde33922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"trec\", split=\"train[:100]\")\n",
    "dataset = dataset.map(lambda x: {\"chunk\": x[\"text\"], \"question\": x[\"text\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf32b21",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mnikiema-github-io",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
